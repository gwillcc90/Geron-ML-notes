{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5853c95",
   "metadata": {},
   "source": [
    "# Chapter 1: The Machine Learning Landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596511e4",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "Machine learning is the science and art of programming a computer to learn from data.\n",
    "\n",
    "Example: The spam filter is a ML algorithm that learns to flag spam given examples of spam and ham emails.\n",
    "\n",
    "The **training set** is the collection (dataset) of examples the computer learns on.\n",
    "\n",
    "Each training example is called a __training instance__ or __sample__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a95dffc",
   "metadata": {},
   "source": [
    "## Why use Machine Learning?\n",
    " - Some problems require list of rules and constant updates; Machine Learning uses mathematics to measure similarities and finds rules mathematically instead of explicit programming.\n",
    " - Some problems are too complex (or long) to do by hand\n",
    " - Machine Learning systems are can be automated to automatically update to catch new patterns\n",
    " - Machine Learning algorithms are inspectable to teach humans about trends in data.\n",
    " \n",
    "**Machine Learning can help humans learn**.\n",
    " \n",
    "**Data Mining** is uncovering patterns in big datasets that were not apparent without the help of a Machine Learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f96fb",
   "metadata": {},
   "source": [
    "## Types of Machine Learning Systems\n",
    "Machine Learning *systems* are categorized based on:\n",
    " - Amount of human supervision\n",
    "  - Supervised\n",
    "  - Unsupervised\n",
    "  - Semi-supervised\n",
    "  - reinforcement\n",
    " - Whether it is automated\n",
    "  - online\n",
    "  - batch\n",
    " - Whether it is being compared to other data or building a model\n",
    "  - instance based\n",
    "  - model based\n",
    "  \n",
    "These criteria are combinable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecbbc7",
   "metadata": {},
   "source": [
    "### Supervised/Unsupervised Learning\n",
    "ML systems are classified based on the amount of human supervision given.\n",
    "The four major categories (Supervised, Unsupervised, etc) are given above.\n",
    "\n",
    "#### Supervised Learning\n",
    "In Supervised Learning problems, the training data includes the **labels**.\n",
    "\n",
    "Def'n. \n",
    "\n",
    "**Labels** are solutions to instances of training data. Labels can be numerical or categorical and are some *target* value. An example of a label in a classification problem is the \"ham\" or \"spam\" class of an email. An example in a regression problem is the median housing price for a district in California (continuous).\n",
    "\n",
    "Typical supervised learning tasks are Regression and Classification.\n",
    "\n",
    "Note: The words: regressor, feature, attribute, and predictor are almost synonymous in Data Science and Machine Learning.\n",
    "\n",
    "Note: The book mentions Logistic Regression. Recall that LR is a classification technique that outputs probability of belonging to each of given classes.\n",
    "\n",
    "Some very important Supervised Learning algorithms:\n",
    " - K-Nearest Neighbors (KNN)\n",
    " - Linear Regression\n",
    " - Logistic Regression (LRC)\n",
    " - Support Vector Machines (SVM)\n",
    " - Decision Trees and Random Forests\n",
    " - Neural Networks\n",
    " \n",
    "#### Unsupervised Learning\n",
    "Training data is unlabelled.\n",
    "\n",
    "Important Unsupervised Learning algorithms:\n",
    "- Clustering\n",
    " - K-means\n",
    " - DBSCAN\n",
    " - Heirachical Cluster Analysis (HCA)\n",
    "- Anomaly detection and novelty detection\n",
    " - One-class SVM\n",
    " - Isolation Forest\n",
    "- Visualization and dimensionality reduction\n",
    " - Principal Component Analysis (PCA)\n",
    " - Kernel PCA\n",
    " - Locally-Linear Embedding (LLE)\n",
    " - t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "- Association rule learning\n",
    " - Apriori\n",
    " - Eclat\n",
    " \n",
    "Example: You can run *clustering* algorithms to detect groups of visitors on websites. You don't know which group they belong to prior, the algorithm finds that out. \"it might notice that 40% of visitors are comic-book-loving males who read every evening, and 20% are sci-fi lovers who only read on weekends. Running a *heirarchical clustering* algorithm may help divide into even smaller subgroups to target your traffic\".\n",
    "\n",
    "Visualization algorithms are good for creating 2D or 3D visualizations of complex, high-dimensional data. This aims to maintain the structure such as spaces between clusters while simplifying understanding of data organization and unrealized patterns.\n",
    "\n",
    "Related to visualization is *dimensionality reduction*: trying to simplify the data without losing information. This is done by merging one or several correlated features into one. Also called **Feature extraction**.\n",
    "\n",
    "Example of **feature extraction**: Merging a car's mileage with its age, $\\dfrac{mileage}{age}$ , to get miles_per_year.\n",
    "\n",
    "Remark: Dimensionality reduction can make your ML system work **faster and better**.\n",
    "\n",
    "Anomaly detection can be used to detect unusual transactions in preventing credit card fraud, or catching manufacturing defects, or automatically removing outliers.\n",
    "\n",
    "*Association learning rule*: to discover relationships among attributes.\n",
    "\n",
    "#### Semisupervised Learning\n",
    "Algorithms that can utilize partially-labelled data - some labelled data and a lot of unlabelled data.\n",
    "\n",
    "Google Photos is an example. Google Photo's algorithm can identify the same person appearing in multiple pictures, so if you label that person in 1 photo, the algorithm will label that person for all photos. \n",
    "\n",
    "Most semisupervised algorithms are combinations of supervised and unsupervised learning algorithms.\n",
    "\n",
    "\n",
    "#### Reinforcement Learning\n",
    "Much different from the other types of learning.\n",
    "\n",
    "The reinforcement learning system deals with an *agent* that \"observes\" the environment, performs an action(s), then gets rewards or penalties (negative rewards) and adopts a *policy*, or *best strategy* to get the most reward over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa12ec",
   "metadata": {},
   "source": [
    "### Batch and Online Learning\n",
    "Whether or not the system is automated.\n",
    "\n",
    "#### Batch Learning (Offline Learning)\n",
    "The system is trained on all available data. This may be impossible if the data is huge, or it may take too long, take up too many resources, etc.\n",
    "\n",
    "#### Online Learning (aka Incremental Learning)\n",
    "Great for systems that use a continuous flow of data. This system is dependent on the learning rate which if too high can forget old data too quickly, or if too low will not react quickly enough.\n",
    "\n",
    "Online Learning systems are better than offline, but must be carefully watched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae694b2f",
   "metadata": {},
   "source": [
    "### Instance Based vs Model Based\n",
    "\"Most ML tasks are about making predictions\", this way is categorizing ML systems on how they generalize.\n",
    "\n",
    "#### Instance-based learning\n",
    "The most trivial way of learning. The system learns examples \"by heart\" and measures similarity of other instances.\n",
    "\n",
    "#### Model-based learning\n",
    "Build a model of examples, then use the model to make predictions. This requires model selection.\n",
    "\n",
    "Suppose you decide to use a linear model, how do you define which parameters $\\theta_0$ ... $\\theta_m$ best fit your model? Use either a *utility (fitness) function* to measure goodness, or a *cost function* to measure badness.\n",
    "\n",
    "Note: For linear regression it is typical to use a cost function to measure the distance between the linear model's predictions (line of best fit)($\\vec{\\hat{y}})$s and the true values ($\\vec{y}$).\n",
    "\n",
    "Now train your model (uncover the parameters that best fit the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d024f4",
   "metadata": {},
   "source": [
    "## Main Challenges of Machine Learning\n",
    "2 things: bad algorithm or bad data\n",
    "\n",
    "The following 4 headers are bad data challenges.\n",
    "### Insufficient Quantity of Training Data\n",
    "Researchers at Microsoft showed in a famous paper that algorithms performed similarly when having large amounts of training data.\n",
    "\n",
    "### Nonrepresentative Training Data\n",
    "It is crucial that training data be representative of new cases you want to generalize to.\n",
    "\n",
    "Note: in the example about GDP and happiness of country, the extreme poor and extreme rich countries were left out. It is crucial to use training data that is representative of the cases you're trying to generalize, but this is difficult because of:\n",
    "\n",
    "**Sampling Noise** - training sample is too small and nonrepresentative data (perhaps as a result of chance) makes bad predictions.\n",
    "Example: Using Mexico, Brazil, and other [poor but happy] countries and Belguim and Luxemborg [rich but unhappy] countries to try and predict Cyprus's happiness level.\n",
    "\n",
    "**Sampling Bias** - Even very large samples can be unrepresentative, say if the sample was not taken randomly.\n",
    "Famous example of sampling bias: The US Literary Digest sampling their readers to predict that the 1936 Presidential candidate Landon would get 57% of the votes, but Roosevelt proceeded to win by landslide. They also did not account for people who did not respond to the survey (*nonresponse bias*).\n",
    "\n",
    "### Poor Quality Data\n",
    "Most data scientists spend lots of time cleaning data: removing outliers, filling missing values or ignoring them, or using different models.\n",
    "\n",
    "### Irrelavent Features\n",
    "**Feature Engineering**: Garbage in, Garbage out. We need to use feature engineering or have bad predictions.\n",
    " - Feature selection: selecting the most useful features\n",
    " - feature extraction: combining existing features\n",
    " - Gather new data and create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b83093f",
   "metadata": {},
   "source": [
    "The following headers are bad algorithm challenges.\n",
    "### Overfitting the Training Data\n",
    "The model performs well on the training data, but poorly on new data. It does not generalize well. The model tries hard to capture the pattern in the training data and predicts poorly on unseen data. We do not want to detect the noise in the data, just generalize. \n",
    "\n",
    "Do not feed uninformative data into a model, like a country's name. A complex model may notice some pattern in the name.\n",
    "\n",
    "Possible solutions to overfitting:\n",
    "- Select a simpler model (like linear over polynomial)\n",
    "- Gather more data\n",
    "- Reduce noise (remove outliers, fill missing)\n",
    "\n",
    "Regularization is controlled by hyperparameters.\n",
    "**Regularization** - *constraining a model to make it simpler and reduce the risk of overfitting.*\n",
    "A hyperparameter is a parameter of the learning algorithm, not of the model itself.\n",
    "\n",
    "### Underfitting the Training Data\n",
    "Model is too simple.\n",
    "\n",
    "fixes:\n",
    "- select a more powerful model\n",
    "- feed better features\n",
    "- reduce constraints (reduct regularization hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb255573",
   "metadata": {},
   "source": [
    "## Testing and Validation\n",
    "The only way to know how well a model generalizes is to try it on new cases.\n",
    "\n",
    "We could just launch the system into production, or we could split our data into training and testing sets and evaluate before launching!\n",
    "\n",
    "If the training error is low but the generalization error is high, the model is overfitting.\n",
    "\n",
    "If the training error and generalization error is high, the model is underfitting.\n",
    "\n",
    "### Hyperparameter Tuning and Model Selection\n",
    "*Holdout validation* - Speaking of training sets, it is good practice to further split the training set into a **validation** set and train several models on the reduced training set, then eval on the validation set. Choose the model with the best performance on the validation dataset, then train it on the *entire* training set and eval on the test set.\n",
    "\n",
    "**Cross-validation** should be used as holdout validation to mitigate evaluation imprecision.\n",
    "\n",
    "Note: The validation and test sets should be as representative as possible to data you expect to see in production.\n",
    "\n",
    "### Data Mismatch\n",
    "Adding another validation set called the train-dev set?\n",
    "\n",
    "No Free Lunch Theorem. There is no reason to think that one model will perform better than another. Need to test on all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec11020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
